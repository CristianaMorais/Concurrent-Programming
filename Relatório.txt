Relatório do projeto de Programação Concorrente

1. Introdução . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
2. Filas concorrentes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2
	2.1.1 Filas baseada em monitores . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . x
	2.1.2 Filas baseada em STM . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . x
	2.1.3 Fila baseada em primitivas atómicas . . . . . . . . . . . . . . . . . . . . . . . . . x
2.2 Análise de execução linearizável . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . x
2.3 Avaliação de desempenho . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . x
2.4 Desafio extra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . x
3. Crawler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . x
4. Conclusão . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . x

---------------------------- Introdução --------------------------------------------------------------

Este trabalho foi realizado no âmbito da disciplina de programação concorrente em que se prentendia implementar filas concorrentes, suportadas por um array, usando 3 técnicas de programação “multi-threaded” distintas, Monitores Java, STM e primitivas atómicas sendo que no caso da implementação baseada em primitivas atómicas o código foi modificado de forma a suportar um esquema de “back-off” exponencial.

---------------------------- Filas baseada em monitores ----------------------------------------------
Em MBQueue é dada uma implementação de uma fila com capacidade fixa baseada no uso do suporte “built-in” em Java para monitores/locks. Já em MBQueueU é uma variante de MBQueue.java de forma a suportar filas sem limite de capacidade.
Ao analisar o ficheiro "MBQueue.java" e antes de efetuar qualquer alteração foi possível verificar que existiam alguns erros:
	
	(foto)

No teste 1, por exemplo, nota-mos que foi obtido o erro "java.lang.NullPointerException" porque no AtomicInteger a está a ser feito set() com uma queue vazia pois o resultado de q.remove() é null uma vez que um monitor faz enter no método add() executa o primeiro bloco synchronized independente do segundo e a thread é adicionada ao conjunto de espera “wait-set” . Outro possivel problema relacionado com o erro poderá ser o facto de uma vez que o lock é libertado, antes de o size ser atualizado, outra thread pode escrever em cima de um elemento que já nao se encontra nao queue, o que não ativa nenhuma exceção.
Eliminado o segundo bloco de synchronized alguns dos erros são corrigidos como podemos observar em baixo.

	(foto)

Um outro erro é o "org.cooperari.errors.CWaitDeadlockError" uma vez existem threads ainda "vivas" e à espera indefinidamente. Isto deve-se ao facto de após o wait() ser aplicado um notify e este entrega uma notificação a apenas uma das threads no “wait-set”, de foram aleatória.
Ao ser alterado para notifyAll() verificamos que todos os testes passam.

No caso de MBQueue as ideias anteriores mantêm-se apenas sendo necessário criar um "newArray" com o dobro do tamanho do array e no final adicionar ao array esse "newArray".

----------------------------- Filas baseada em STM ----------------------------------------------------

(Sara)

----------------------------- Fila baseada em primitivas atómicas -------------------------------------

Visto que a classe Rooms ja continha um parâmetro de backoff e uma lógica de suporte associada. 
As variáveis head e tail são atómicas e pontos de sincronização que os elementos devem ser adicionados ou removido, e quando são ativados garantem que uma ordem na execução mas pode causar sobreposição na ocorrência de outras ações em outros métodos o que pode causar erros.
Assim sendo, a ideia de implementação foi que, tendo em conta estes fatores, a cada iteração no while uma thread faz enter num quarto, executa as ações e faz leave desse quarto( em que 0 foi associado ao metodo add, 1 ao remove e 2 ao size), sendo que assim que esta entra no quarto nao existe nenhuma condição que limite o número de threads naquele quarto, garantindo que pelo menos uma thread prossegue e a saída no fim do while é garatida, sendo que é garantido também que caso a operação não seja bem sucedida a saí	da do quarto é garantida visto que é necessário garantir que apenas um método possa ser executado ao mesmo tempo, para manter então a ordem correta de execução.
Sobre o uso do backoff é necessário referir que as entradas nas são feitas dentro de um ciclo de espera ativa que garante que enquanto a sua funcionalidade não seja concluída, múltiplas chamadas serão feitas a entrada na sala o que ativa este mecanismo presente em Rooms.  

Já em LBQueueU é implementada de forma a suportar filas sem capacidade fixa. Para lidar com o redimensionamento do array foi usado um objecto AtomicBoolean que funcione como “flag” de exclusão mútua no acesso ao array, possibilitando o redimensionamento do mesmo, definido como addElementFlag.compareAndSet(false, true) que coloca as outras threads em espera ativa.

----------------------------- Análise de execução linearizável ----------------------------------------

Os benchmarks foram executados em máquinas com as seguintes caraterísticas:
 	CPU : 
 	RAM : 
 	Sistema operativo: UBUNTU

------------------------------ Desafio extra ----------------------------------------------------------

Não realizamos o desafio extra.

------------------------------- Crawler ---------------------------------------------------------------



-------------------------------- Conclusão ------------------------------------------------------------

Com este trabalho conseguimos aprofundar melhor a implementa filas concorrentes suportadas por um array através destas três técnicas de
programação “multi-threaded” . Podemos verificar que o aumento de número de threads faz com que as implementações reduzam o seu desempenho, o backoff melhora significativamente o desempenho,quando comparado com a alternativa de espera ativa, e que a utilização de muitas threads significa uma maior sincronização mas um aumento na complexidade de execução da parte do computador.